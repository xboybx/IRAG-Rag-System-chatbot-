<p align="center">
  <img src="frontend/public/IRAG logos.png" alt="IRAG Logo" width="120" />
</p>

<h1 align="center">IRAG â€” Intelligent Retrieval-Augmented Generation Chatbot</h1>

<p align="center">
  <strong>An AI-powered chatbot that combines multiple LLMs with RAG technology and real-time web search to deliver intelligent, context-aware answers from your own documents.</strong>
</p>

<p align="center">
  <a href="https://iragchat.vercel.app">ğŸŒ Live Demo</a> â€¢
  <a href="#features">âœ¨ Features</a> â€¢
  <a href="#how-rag-works">ğŸ§  How RAG Works</a> â€¢
  <a href="#tech-stack">ğŸ› ï¸ Tech Stack</a> â€¢
  <a href="#getting-started">ğŸš€ Getting Started</a>
</p>

---

## ğŸ“– What is IRAG?

**IRAG** (Intelligent RAG) is a full-stack AI chatbot application that goes beyond simple question-and-answer interactions. It uses **Retrieval-Augmented Generation (RAG)** to let users upload their own documents (PDFs, Word files, spreadsheets, CSVs, text files) and then ask questions about them â€” getting accurate, context-grounded answers powered by AI.

Think of it as having a personal research assistant that has actually *read* your documents and can answer questions about them, cite relevant sections, and combine that knowledge with its general understanding of the world.

---

## â“ Why IRAG?

Traditional chatbots only know what they were trained on. They can't read your files, they hallucinate facts, and they have no memory of your previous conversations.

**IRAG solves this by:**

| Problem | IRAG's Solution |
|---|---|
| AI doesn't know your data | **Upload documents** â€” IRAG reads, chunks, and indexes them |
| AI hallucinates answers | **RAG retrieval** â€” answers are grounded in your actual documents |
| AI knowledge is outdated | **Web Search** â€” fetches real-time information from the internet |
| AI forgets context | **Conversation memory** â€” maintains context with smart summarization |
| Single model limitations | **Multi-model fallback** â€” round-robin across multiple free AI models |
| Slow responses | **Streaming** â€” real-time typewriter-style response rendering |

---

## âœ¨ Features

### ğŸ¤– AI & RAG Core
- **Multi-Model Support** â€” Uses OpenRouter to access multiple AI models (Solar Pro 3, Arcee Trinity, LFM 2.5) with automatic round-robin fallback
- **RAG Document Q&A** â€” Upload documents and ask questions about them with vector-similarity-based context retrieval
- **Web Search Integration** â€” Powered by Tavily API for real-time web search (manual or auto-triggered)
- **Streaming Responses** â€” Real-time typewriter-style response delivery via chunked transfer encoding
- **Conversation Memory** â€” Smart context management with automatic history summarization for long conversations
- **Context-Aware Answers** â€” Combines document context + web search results + conversation history for comprehensive answers

### ğŸ“„ Document Processing
- **Multi-Format Support** â€” PDF, DOCX (Word), XLSX (Excel), CSV, TXT, and JSON
- **Intelligent Chunking** â€” Uses LangChain's `RecursiveCharacterTextSplitter` with 1000 character chunks and 200 character overlap
- **Vector Embeddings** â€” Generates embeddings using OpenAI's `text-embedding-3-small` model
- **MongoDB Atlas Vector Search** â€” Stores and queries embeddings using native MongoDB vector search
- **Cloud Storage** â€” Files are stored on ImageKit CDN for fast, reliable access

### ğŸ” Authentication & Security
- **JWT-Based Auth** â€” Dual token strategy with short-lived access tokens and HTTP-only refresh token cookies
- **Secure Cookies** â€” SameSite=None, Secure, HTTP-only cookies for cross-domain auth
- **Token Auto-Refresh** â€” Seamless token refresh via Axios interceptors
- **Protected Routes** â€” Middleware-based route protection on the backend

### ğŸ¨ Frontend Experience
- **Modern UI** â€” Glassmorphism design with smooth animations and responsive layouts
- **Dark Mode** â€” Full dark mode support via `next-themes`
- **Mobile Responsive** â€” Fully responsive across all device sizes
- **Conversation Sidebar** â€” Manage, switch, and delete conversations
- **Engaging Loading Screen** â€” Animated card-stack loader showcasing app features while the backend wakes up
- **Redux State Management** â€” Centralized state with Redux Toolkit for auth, chat, conversations, and UI
- **Markdown Rendering** â€” AI responses rendered with full Markdown support including syntax highlighting

---

## ğŸ§  How RAG Works

RAG (Retrieval-Augmented Generation) is the core technology that makes IRAG special. Here's how it works step by step:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG PIPELINE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ“„ DOCUMENT UPLOAD PHASE                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Upload   â”‚â”€â”€â”€â–¶â”‚  Parse   â”‚â”€â”€â”€â–¶â”‚  Chunk    â”‚â”€â”€â”€â–¶â”‚  Embed &    â”‚  â”‚
â”‚  â”‚  File     â”‚    â”‚  Text    â”‚    â”‚  Text     â”‚    â”‚  Store      â”‚  â”‚
â”‚  â”‚(PDF/DOCX) â”‚    â”‚(mammoth, â”‚    â”‚(LangChain â”‚    â”‚(MongoDB     â”‚  â”‚
â”‚  â”‚           â”‚    â”‚ pdf-parseâ”‚    â”‚ 1000 char â”‚    â”‚ Atlas +     â”‚  â”‚
â”‚  â”‚           â”‚    â”‚ xlsx)    â”‚    â”‚ + 200     â”‚    â”‚ Vector      â”‚  â”‚
â”‚  â”‚           â”‚    â”‚          â”‚    â”‚ overlap)  â”‚    â”‚ Index)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â”‚  ğŸ’¬ QUERY PHASE                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  User     â”‚â”€â”€â”€â–¶â”‚  Embed   â”‚â”€â”€â”€â–¶â”‚  Vector   â”‚â”€â”€â”€â–¶â”‚  Inject     â”‚  â”‚
â”‚  â”‚  Asks     â”‚    â”‚  Query   â”‚    â”‚  Search   â”‚    â”‚  Context    â”‚  â”‚
â”‚  â”‚  Question â”‚    â”‚          â”‚    â”‚  (cosine  â”‚    â”‚  into AI    â”‚  â”‚
â”‚  â”‚           â”‚    â”‚          â”‚    â”‚  similar- â”‚    â”‚  Prompt     â”‚  â”‚
â”‚  â”‚           â”‚    â”‚          â”‚    â”‚  ity)     â”‚    â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚                           â”‚
â”‚                                         â–¼                           â”‚
â”‚                              Score > 0.35?                          â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”                         â”‚
â”‚                              â”‚ YESâ”‚  â”‚ NO â”‚                         â”‚
â”‚                              â””â”€â”€â”¬â”€â”˜  â””â”€â”€â”¬â”€â”˜                         â”‚
â”‚                                 â”‚       â”‚                           â”‚
â”‚                          Use RAG    Normal AI                       â”‚
â”‚                          Context    Response                        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step-by-Step

1. **Upload** â€” User uploads a document (PDF, DOCX, XLSX, CSV, TXT, JSON)
2. **Parse** â€” The server extracts raw text from the file using specialized parsers (`pdf-parse`, `mammoth`, `xlsx`, `d3-dsv`)
3. **Chunk** â€” Text is split into overlapping chunks of ~1000 characters using LangChain's `RecursiveCharacterTextSplitter`
4. **Embed** â€” Each chunk is converted into a 1536-dimensional vector using OpenAI's `text-embedding-3-small` model
5. **Store** â€” Vectors are stored in MongoDB Atlas with a Vector Search Index
6. **Query** â€” When the user asks a question, their query is also converted into a vector
7. **Search** â€” MongoDB Atlas Vector Search finds the top 3 most similar chunks (cosine similarity)
8. **Threshold** â€” Only chunks with a similarity score > 0.35 are considered relevant
9. **Inject** â€” Relevant chunks are injected into the AI prompt as system context
10. **Generate** â€” The AI generates an answer grounded in the retrieved document context

---

## ğŸ› ï¸ Tech Stack

### Frontend
| Technology | Purpose |
|---|---|
| **Next.js 16** | React framework with App Router, SSR, and API rewrites |
| **TypeScript** | Type-safe frontend development |
| **Redux Toolkit** | Global state management (auth, chat, conversations, UI) |
| **Tailwind CSS v4** | Utility-first styling with custom design tokens |
| **Shadcn/UI** | Pre-built accessible UI components |
| **React Markdown** | Rendering AI responses with full Markdown + syntax highlighting |
| **Lucide React** | Beautiful, consistent iconography |

### Backend
| Technology | Purpose |
|---|---|
| **Node.js + Express 5** | REST API server |
| **MongoDB + Mongoose** | Database with Vector Search for RAG |
| **OpenRouter API** | Multi-model AI gateway (Solar Pro 3, Arcee Trinity, etc.) |
| **OpenAI SDK** | Embeddings generation (`text-embedding-3-small`) |
| **Tavily API** | Real-time web search integration |
| **LangChain** | Document parsing and text splitting |
| **ImageKit** | Cloud file storage CDN |
| **JWT + bcrypt** | Authentication and password hashing |
| **Multer** | File upload handling (in-memory buffer) |

### Infrastructure
| Service | Purpose |
|---|---|
| **Vercel** | Frontend hosting |
| **Render** | Backend hosting (free tier) |
| **MongoDB Atlas** | Cloud database with Vector Search |
| **ImageKit** | File/image CDN |

---

## ğŸ“ Project Structure

```
IRAG/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Controllers/
â”‚   â”‚   â”œâ”€â”€ AIcontroller.js          # Chat, upload, conversations, messages
â”‚   â”‚   â””â”€â”€ UserController.js        # Register, login, logout, refresh, profile
â”‚   â”œâ”€â”€ Middleware/
â”‚   â”‚   â”œâ”€â”€ AuthMiddlware.js         # JWT verification middleware
â”‚   â”‚   â””â”€â”€ multer.middleware.js      # File upload handling (memory storage)
â”‚   â”œâ”€â”€ Routes/
â”‚   â”‚   â”œâ”€â”€ ai.Routes.js             # /ai/* routes
â”‚   â”‚   â””â”€â”€ auth.routes.js           # /user/* routes
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ConversationModel.js     # Conversation schema (title, files, model)
â”‚   â”‚   â”œâ”€â”€ MessageModel.js          # Message schema (with RAG citations, feedback)
â”‚   â”‚   â”œâ”€â”€ EmbeddingModel.js        # Vector embedding schema
â”‚   â”‚   â”œâ”€â”€ FileModel.js             # Uploaded file metadata
â”‚   â”‚   â””â”€â”€ UserModel.js             # User schema with hashed passwords
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ai.service.js            # Multi-model AI with round-robin fallback
â”‚   â”‚   â”œâ”€â”€ rag.service.js           # RAG: vector search + context injection
â”‚   â”‚   â”œâ”€â”€ embedding.service.js     # Embedding generation for chunks & queries
â”‚   â”‚   â”œâ”€â”€ webSearch.service.js     # Tavily web search integration
â”‚   â”‚   â””â”€â”€ imagekit.service.js      # ImageKit file upload
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ ChatContext.js           # Fetch conversation context from DB
â”‚   â”‚   â”œâ”€â”€ FileParser.js            # Multi-format file text extraction
â”‚   â”‚   â””â”€â”€ systemPrompt.js          # AI system prompt
â”‚   â””â”€â”€ app.js                       # Express server entry point
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Landing page (home)
â”‚   â”‚   â”œâ”€â”€ layout.tsx               # Root layout with providers
â”‚   â”‚   â”œâ”€â”€ chat/[[...id]]/page.tsx  # Main chat interface
â”‚   â”‚   â”œâ”€â”€ login/page.tsx           # Login page
â”‚   â”‚   â”œâ”€â”€ register/page.tsx        # Registration page
â”‚   â”‚   â””â”€â”€ profile/page.tsx         # User profile page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ AppLoader.tsx            # Animated card-stack loading screen
â”‚   â”‚   â”œâ”€â”€ AuthWrapper.tsx          # Auth check + route protection
â”‚   â”‚   â”œâ”€â”€ ConversationSidebar.tsx  # Sidebar with conversation history
â”‚   â”‚   â””â”€â”€ MessageContent.tsx       # Markdown message renderer
â”‚   â”œâ”€â”€ Redux/
â”‚   â”‚   â”œâ”€â”€ Features/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chatslice.ts         # Chat messages state
â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationHistorySlice.ts # Conversation list state
â”‚   â”‚   â”‚   â”œâ”€â”€ UIslice.ts           # Sidebar, modals UI state
â”‚   â”‚   â”‚   â””â”€â”€ UserSlice.ts         # Auth state (login, register, refresh)
â”‚   â”‚   â”œâ”€â”€ Store.ts                 # Redux store configuration
â”‚   â”‚   â”œâ”€â”€ axiosInstance.ts         # Axios with token refresh interceptor
â”‚   â”‚   â””â”€â”€ hooks.ts                 # Typed Redux hooks
â”‚   â””â”€â”€ next.config.ts               # API rewrites to backend
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** v18+
- **MongoDB Atlas** account (with Vector Search index configured)
- **OpenRouter** API key (free tier available)
- **ImageKit** account (for file storage)
- **Tavily** API key (for web search, optional)

### 1. Clone the Repository

```bash
git clone https://github.com/xboybx/IRAG-Rag-System-chatbot-.git
cd IRAG-Rag-System-chatbot-
```

### 2. Backend Setup

```bash
cd backend
npm install
```

Create a `.env` file in the `backend/` directory:

```env
PORT=5000
MONGO_URI=your_mongodb_atlas_connection_string
JWT_SECRET=your_jwt_secret_key
JWT_REFRESH_SECRET=your_refresh_token_secret
OPEN_ROUTER_API_KEY=your_openrouter_api_key
IMAGEKIT_PUBLIC_KEY=your_imagekit_public_key
IMAGEKIT_PRIVATE_KEY=your_imagekit_private_key
IMAGEKIT_URL_ENDPOINT=your_imagekit_url_endpoint
TAVILY_API_KEY=your_tavily_api_key
FRONTEND_URL=http://localhost:3000
SITE_URL=http://localhost:3000
SITE_NAME=IRAG
```

Start the backend:

```bash
npm run dev
```

### 3. Frontend Setup

```bash
cd frontend
npm install
```

Create a `.env` file in the `frontend/` directory:

```env
NEXT_PUBLIC_BACKEND_URL=http://localhost:5000
```

Start the frontend:

```bash
npm run dev
```

### 4. MongoDB Atlas Vector Search Index

You **must** create a Vector Search Index on the `embeddings` collection in MongoDB Atlas for the RAG functionality to work.

**Index Configuration:**

```json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1536,
      "similarity": "cosine"
    },
    {
      "type": "filter",
      "path": "fileId"
    }
  ]
}
```

Name the index: `vector_index`

---

## ğŸ”Œ API Reference

### Auth Routes (`/user`)

| Method | Endpoint | Description | Auth |
|---|---|---|---|
| `POST` | `/user/register` | Register new user | âŒ |
| `POST` | `/user/login` | Login user | âŒ |
| `POST` | `/user/logout` | Logout user | âœ… |
| `GET` | `/user/me` | Get current user profile | âœ… |
| `POST` | `/user/refresh` | Refresh access token | âŒ (uses cookie) |

### AI Routes (`/ai`)

| Method | Endpoint | Description | Auth |
|---|---|---|---|
| `POST` | `/ai/chat/:conversationId` | Send message (streaming) | âœ… |
| `POST` | `/ai/create-conversation` | Create new conversation | âœ… |
| `POST` | `/ai/dataset-upload` | Upload document for RAG | âœ… |
| `GET` | `/ai/history` | Get all conversations | âœ… |
| `DELETE` | `/ai/history/:conversationId` | Delete conversation | âœ… |
| `GET` | `/ai/chat/:conversationId` | Get messages for conversation | âœ… |

---

## ğŸ“„ Supported File Formats

| Format | Extension | Parser Used |
|---|---|---|
| PDF | `.pdf` | LangChain `PDFLoader` |
| Word Document | `.docx` | `mammoth` |
| Excel Spreadsheet | `.xlsx` | `xlsx` (SheetJS) |
| CSV | `.csv` | `d3-dsv` |
| Plain Text | `.txt` | Native `Buffer.toString()` |
| JSON | `.json` | Native `Buffer.toString()` |

---

## ğŸ¤– AI Models

IRAG uses **OpenRouter** as a gateway to access multiple free AI models:

| Model | ID | Mode |
|---|---|---|
| Solar Pro 3 | `upstage/solar-pro-3:free` | Auto / Manual |
| Arcee Trinity Large | `arcee-ai/trinity-large-preview:free` | Auto / Manual |
| LFM 2.5 1.2B Thinking | `liquid/lfm-2.5-1.2b-thinking:free` | Auto / Manual |

- **Auto Mode**: Round-robin across all available models with automatic fallback
- **Manual Mode**: Select a specific model from the dropdown

---

## ğŸŒ Deployment

| Component | Platform | URL |
|---|---|---|
| Frontend | Vercel | [iragchat.vercel.app](https://iragchat.vercel.app) |
| Backend | Render (Free Tier) | Configured via `NEXT_PUBLIC_BACKEND_URL` |
| Database | MongoDB Atlas | Cloud-hosted with Vector Search |
| File Storage | ImageKit | CDN-backed file delivery |

> **Note:** The backend is hosted on Render's free tier, which spins down after inactivity. The first request may take 30-60 seconds while the server wakes up. The app includes a backend wake-up mechanism and an engaging loading screen to handle this gracefully.

---

## ğŸ‘¨â€ğŸ’» Developer

Built with â¤ï¸ by **Jaswanth**

---

## ğŸ“ License

This project is for educational and portfolio purposes.
